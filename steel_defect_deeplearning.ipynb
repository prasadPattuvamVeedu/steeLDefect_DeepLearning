{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb29645d-c246-4af6-b680-2bfcd0e82f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18,ResNet18_Weights,inception_v3,Inception_V3_Weights\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44143cdd-9a71-4ee3-b67f-c396c581a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3add6f-c670-4b05-9d03-905ecc3fba6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container{ width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687b377e-b8d6-4d90-a290-dc6e8358650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000f6bf48.jpg</td>\n",
       "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002af848d.jpg</td>\n",
       "      <td>290800 6 291055 13 291311 15 291566 18 291822 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030401a5.jpg</td>\n",
       "      <td>186833 1 187089 3 187344 6 187600 7 187855 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>008621629.jpg</td>\n",
       "      <td>215548 3 215798 9 216051 12 216306 13 216560 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>012f26693.jpg</td>\n",
       "      <td>35258 2 35513 5 35768 8 36023 11 36277 15 3653...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  000f6bf48.jpg  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
       "1  002af848d.jpg  290800 6 291055 13 291311 15 291566 18 291822 ...\n",
       "2  0030401a5.jpg  186833 1 187089 3 187344 6 187600 7 187855 10 ...\n",
       "3  008621629.jpg  215548 3 215798 9 216051 12 216306 13 216560 1...\n",
       "4  012f26693.jpg  35258 2 35513 5 35768 8 36023 11 36277 15 3653..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(r\"Data/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba61238-24ec-4fad-9128-e805504cc894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d1bc56-db25-4c09-af95-569b64b34779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0025bde0c.jpg</td>\n",
       "      <td>315139 8 315395 15 315651 16 315906 17 316162 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08b40a161.jpg</td>\n",
       "      <td>178410 2 178664 7 178918 11 179172 20 179426 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1795867f2.jpg</td>\n",
       "      <td>266115 46 266370 51 266625 55 266880 60 267136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190190a6f.jpg</td>\n",
       "      <td>18811 1 19065 5 19320 8 19574 12 19829 15 2008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2fcfb108a.jpg</td>\n",
       "      <td>230653 3 230904 8 231157 11 231413 11 231616 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  0025bde0c.jpg  315139 8 315395 15 315651 16 315906 17 316162 ...\n",
       "1  08b40a161.jpg  178410 2 178664 7 178918 11 179172 20 179426 2...\n",
       "2  1795867f2.jpg  266115 46 266370 51 266625 55 266880 60 267136...\n",
       "3  190190a6f.jpg  18811 1 19065 5 19320 8 19574 12 19829 15 2008...\n",
       "4  2fcfb108a.jpg  230653 3 230904 8 231157 11 231413 11 231616 6..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(r\"Data/val.csv\")\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be6313-e353-4e93-b873-da0502732d0a",
   "metadata": {},
   "source": [
    "<h2 style=\"\n",
    "    background:#1f77b4;\n",
    "    color:white;\n",
    "    padding:10px;\n",
    "    border-radius:8px;\n",
    "\">\n",
    "RLE decode function\n",
    "</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd28e1d6-4e1c-445b-bcc0-b94ce15896c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rleDecode(mask_rle,shape=(256,1600)):\n",
    "    if pd.isna(mask_rle):\n",
    "       return np.zeros(shape,dtype=np.uint8)\n",
    "    s = mask_rle.split()\n",
    "    starts = np.array(s[0::2],dtype=int)-1\n",
    "    pos    = np.array(s[1::2],dtype=int)\n",
    "    ends   = starts+pos\n",
    "\n",
    "    img = np.zeros(shape[0]*shape[1],dtype=np.uint8)\n",
    "    for start_pos,end_pos in zip(starts,ends):\n",
    "         img[start_pos:end_pos] = 1\n",
    "    return img.reshape(256,1600,order='F')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721e15e-ed61-461a-b93b-701b46407651",
   "metadata": {},
   "source": [
    "<h2 style=\"\n",
    "    background:#1f77b4;\n",
    "    color:white;\n",
    "    padding:10px;\n",
    "    border-radius:8px;\n",
    "\">\n",
    "Dataset Function\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c5c231-5b58-401e-b706-3eb236b7cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self,image_dir,csv_path):\n",
    "         self.csv_path = csv_path\n",
    "         self.df = pd.read_csv(csv_path)\n",
    "         self.image_dir=image_dir\n",
    "         self.imageid_unique = self.df.ImageId.unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        self.image_len = len(self.imageid_unique)\n",
    "        return self.image_len\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_id   = self.imageid_unique[idx]\n",
    "        image_path = os.path.join(self.image_dir,image_id)\n",
    "        image      = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        image      = image/255\n",
    "        image      = torch.tensor(image).unsqueeze(0)\n",
    "       \n",
    "        rows        = self.df[self.df.ImageId==image_id]\n",
    "        mask = np.zeros((256,1600))\n",
    "\n",
    "        for _,row in rows.iterrows():\n",
    "            if not pd.isna(row.EncodedPixels):\n",
    "                mask += rleDecode(row.EncodedPixels)\n",
    "        mask = np.clip(mask, 0, 1)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)\n",
    "\n",
    "        return image.float(), mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8fe84cf-3c96-43d5-8d76-f082c191ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SteelDataset(\n",
    "#     \"Data/train_images\",\n",
    "#     \"Data/train.csv\")\n",
    "# image,mask=dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556582ed-d37d-412c-9afc-48137641d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d5dc44-19d3-4a2c-b1a1-571d9a349d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c3f8d3-8c48-4b9a-85bf-882f67cee690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SteelDataset(\"Data/train_images\",\"Data/train.csv\")\n",
    "trainData_loader = DataLoader(dataset=train_dataset,batch_size=4,shuffle=True,drop_last=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f13b5e4-b887-4557-8d19-d059200faf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac27d0-599b-480c-8bf8-9f5297e62bf8",
   "metadata": {},
   "source": [
    "<h2>Conv2d calculation</h2>\n",
    "<img src=\"image/calc3.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a7a6097-06a6-4015-bb9a-7779ed67ca71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc74bef-9230-4773-baf9-34e2760e5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47ebed8e-402b-4bc9-acf4-6ab3bf2e93de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372348c-d091-4796-9220-bda181c3199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "__BY DOING RESNET ITS SHAPPE BECOME 1,512,8,50 TO INCREASE THE SIZE WE NEED TO UP SAMPLING IT BY DOING DECODER CLASS BELOW THE FINAL SHAPE WILL BECOM 1,1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "143e8711-c943-49d2-9578-bc1ada6c13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        self.up1 = nn.ConvTranspose2d(512,256,2,2)\n",
    "        self.up2 = nn.ConvTranspose2d(256,128,2,2)\n",
    "        self.up3 = nn.ConvTranspose2d(128,64,2,2)\n",
    "        self.up4 = nn.ConvTranspose2d(64,32,2,2)\n",
    "        self.up5 = nn.ConvTranspose2d(32,16,2,2)\n",
    "        self.final = nn.Conv2d(16,1,kernel_size=1)\n",
    "        # ð» = 128,w = 800, padding=0,output=1 =>1,32,128,800 to 1,1,128,800\n",
    "    def forward(self,x):\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)\n",
    "        x = self.up4(x)\n",
    "        return seld.final(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797fbde-2b3f-490d-9c7a-bafb4569ba3c",
   "metadata": {},
   "source": [
    "<img src=\"image/calc.png\" width=\"100%\">\n",
    "\n",
    "<h2>ConvTranspose2d calculation</h2>\n",
    "<img src=\"image/calc2.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d20d7308-6c71-48ff-abfe-d692bbeea7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self,resnet_model):\n",
    "        super.__init__()\n",
    "        self.resnet_model = resnet_model\n",
    "        self.Decoder = Decoder()\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.encoder.layer1(x)\n",
    "        x = self.encoder.layer2(x)\n",
    "        x = self.encoder.layer3(x)\n",
    "        x = self.encoder.layer4(x)\n",
    "\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25983092-185b-4632-b4e5-ef440e61d663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
